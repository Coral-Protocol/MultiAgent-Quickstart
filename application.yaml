applications:
  - id: "app"
    name: "Default Application"
    description: "Default application for testing"
    privacyKeys:
      - "priv"

registry:
  interface:
    options:
      - name: "MODEL_API_KEY"
        type: "string"
        description: "API key for the model provider"
      - name: "MODEL_NAME"
        type: "string"
        description: "What model to use (e.g 'gpt-4.1')"
        default: "gpt-4.1"
      - name: "MODEL_PROVIDER"
        type: "string"
        description: "What model provider to use (e.g 'openai', etc)"
        default: "openai"
      - name: "MODEL_TOKEN_LIMIT"
        type: "number"
        description: "Max tokens to use"
        default: 16000
      - name: "MODEL_TEMPERATURE"
        type: "string"
        description: "What model temperature to use"
        default: "0.3"

    runtime:
      type: "executable"
      command: [ "bash", "-c", "../run_agent.sh ../agents/interface/main.py" ]
      environment:
        - option: "API_KEY"
        - option: "MODEL_NAME"
        - option: "MODEL_PROVIDER"
        - option: "MODEL_TOKEN_LIMIT"
        - option: "MODEL_TEMPERATURE"

  github:
    options:
      - name: "MODEL_API_KEY"
        type: "string"
        description: "API key for the model provider"
      - name: "GITHUB_PERSONAL_ACCESS_TOKEN"
        type: "string"
        description: "Github token for the service"
      - name: "MODEL_NAME"
        type: "string"
        description: "What model to use (e.g 'gpt-4.1')"
        default: "gpt-4.1"
      - name: "MODEL_PROVIDER"
        type: "string"
        description: "What model provider to use (e.g 'openai', etc)"
        default: "openai"
      - name: "MODEL_TOKEN_LIMIT"
        type: "number"
        description: "Max tokens to use"
        default: 16000
      - name: "MODEL_TEMPERATURE"
        type: "string"
        description: "What model temperature to use"
        default: "0.3"
    runtime:
      type: "executable"
      command: [ "bash", "-c", "../run_agent.sh ../agents/github/main.py" ]
      environment:
        - option: "MODEL_API_KEY"
        - option: "GITHUB_PERSONAL_ACCESS_TOKEN"
        - option: "MODEL_NAME"
        - option: "MODEL_PROVIDER"
        - option: "MODEL_TOKEN_LIMIT"
        - option: "MODEL_TEMPERATURE"

  firecrawl:
    options:
      - name: "MODEL_API_KEY"
        type: "string"
        description: "API key for the model provider"
      - name: "FIRECRAWL_API_KEY"
        type: "string"
        description: "FIRECRAWL API KEY for the service"
      - name: "MODEL_NAME"
        type: "string"
        description: "What model to use (e.g 'gpt-4.1')"
        default: "gpt-4.1"
      - name: "MODEL_PROVIDER"
        type: "string"
        description: "What model provider to use (e.g 'openai', etc)"
        default: "openai"
      - name: "MODEL_TOKEN_LIMIT"
        type: "number"
        description: "Max tokens to use"
        default: 16000
      - name: "MODEL_TEMPERATURE"
        type: "string"
        description: "What model temperature to use"
        default: "0.3"
    runtime:
      type: "executable"
      command: ["bash", "-c", "../run_agent.sh ../agents/firecrawl/main.py"]
      environment:
        - option: "API_KEY"
        - option: "FIRECRAWL_API_KEY"
        - option: "MODEL_NAME"
        - option: "MODEL_PROVIDER"
        - option: "MODEL_TOKEN_LIMIT"
        - option: "MODEL_TEMPERATURE"
